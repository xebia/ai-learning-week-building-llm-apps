{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24424fb",
   "metadata": {},
   "source": [
    "# 3. Creating a Simple Agent\n",
    "\n",
    "In this notebook, we will learn how to create a simple agent using the `google-adk` library. Agents are AI systems that can perform tasks by reasoning, planning, and interacting with tools or APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd43b0a",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "We will start by importing the necessary libraries and defining constants for our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ea627ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define constants\n",
    "APP_NAME = \"agent_comparison_app\"\n",
    "USER_ID = \"test_user_456\"\n",
    "SESSION_ID_TOOL_AGENT = \"session_tool_agent_xyz\"\n",
    "SESSION_ID_SCHEMA_AGENT = \"session_schema_agent_xyz\"\n",
    "MODEL_NAME = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad41a29",
   "metadata": {},
   "source": [
    "## Step 2: Define Input and Output Schemas\n",
    "\n",
    "We will define the input schema for both agents and the output schema for the second agent. These schemas ensure that the agents understand the structure of the data they process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "159de480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountryInput(BaseModel):\n",
    "    country: str = Field(description=\"The country to get information about.\")\n",
    "\n",
    "class CapitalInfoOutput(BaseModel):\n",
    "    capital: str = Field(description=\"The capital city of the country.\")\n",
    "    population_estimate: str = Field(description=\"An estimated population of the capital city.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf21d6",
   "metadata": {},
   "source": [
    "## Step 3: Define a Tool\n",
    "\n",
    "The first agent will use a tool to retrieve the capital city of a country. Here, we define the tool as a Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8491dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_capital_city(country: str) -> str:\n",
    "    \"\"\"Retrieves the capital city of a given country.\"\"\"\n",
    "    country_capitals = {\n",
    "        \"united states\": \"Washington, D.C.\",\n",
    "        \"canada\": \"Ottawa\",\n",
    "        \"france\": \"Paris\",\n",
    "        \"japan\": \"Tokyo\"\n",
    "    }\n",
    "    return country_capitals.get(country.lower(), f\"Sorry, I couldn't find the capital for {country}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f9b00",
   "metadata": {},
   "source": [
    "## Step 4: Configure Agents\n",
    "\n",
    "We will now configure two agents:\n",
    "1. An agent that uses the `get_capital_city` tool.\n",
    "2. An agent that provides structured information without using tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "744db88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_agent_with_tool = LlmAgent(\n",
    "    model=MODEL_NAME,\n",
    "    name=\"capital_agent_tool\",\n",
    "    description=\"Retrieves the capital city using a specific tool.\",\n",
    "    instruction=\"\"\"You are a helpful agent that provides the capital city of a country using a tool.\n",
    "The user will provide the country name in a JSON format like {\\\"country\\\": \\\"country_name\\\"}.\n",
    "1. Extract the country name.\n",
    "2. Use the `get_capital_city` tool to find the capital.\n",
    "3. Respond clearly to the user, stating the capital city found by the tool.\"\"\",\n",
    "    tools=[get_capital_city],\n",
    "    input_schema=CountryInput,\n",
    "    output_key=\"capital_tool_result\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instruction = f\"\"\"You are an agent that provides country information.\n",
    "The user will provide the country name in a JSON format like {{\\\"country\\\": \\\"country_name\\\"}}.\n",
    "Respond ONLY with a JSON object matching this exact schema:\n",
    "{json.dumps(CapitalInfoOutput.model_json_schema(), indent=2)}\n",
    "Use your knowledge to determine the capital and estimate the population. Do not use any tools.\n",
    "\"\"\"\n",
    "\n",
    "structured_info_agent_schema = LlmAgent(\n",
    "    model=MODEL_NAME,\n",
    "    name=\"structured_info_agent_schema\",\n",
    "    description=\"Provides capital and estimated population in a specific JSON format.\",\n",
    "    instruction=instruction,\n",
    "    input_schema=CountryInput,\n",
    "    output_schema=CapitalInfoOutput,\n",
    "    output_key=\"structured_info_result\",\n",
    "    disallow_transfer_to_parent=True,\n",
    "    disallow_transfer_to_peers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383abd5a",
   "metadata": {},
   "source": [
    "## Step 5: Set Up Session Management and Runners\n",
    "\n",
    "We will create sessions for each agent and set up runners to manage their interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41e1184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_service = InMemorySessionService()\n",
    "\n",
    "session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID_TOOL_AGENT)\n",
    "session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID_SCHEMA_AGENT)\n",
    "\n",
    "capital_runner = Runner(\n",
    "    agent=capital_agent_with_tool,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "structured_runner = Runner(\n",
    "    agent=structured_info_agent_schema,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24327de2",
   "metadata": {},
   "source": [
    "## Step 6: Define Agent Interaction Logic\n",
    "\n",
    "We will define a function to interact with the agents and print their responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d12f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_agent_and_print(runner_instance: Runner, agent_instance: LlmAgent, session_id: str, query_json: str):\n",
    "    user_content = types.Content(role='user', parts=[types.Part(text=query_json)])\n",
    "    async for event in runner_instance.run_async(user_id=USER_ID, session_id=session_id, new_message=user_content):\n",
    "        if event.is_final_response() and event.content and event.content.parts:\n",
    "            print(event.content.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed36c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_agent_and_print(\n",
    "    runner_instance: Runner,\n",
    "    agent_instance: LlmAgent,\n",
    "    session_id: str,\n",
    "    query_json: str\n",
    "):\n",
    "    \"\"\"Sends a query to the specified agent/runner and prints results.\"\"\"\n",
    "    print(f\"\\n>>> Calling Agent: '{agent_instance.name}' | Query: {query_json}\")\n",
    "\n",
    "    user_content = types.Content(role='user', parts=[types.Part(text=query_json)])\n",
    "\n",
    "    final_response_content = \"No final response received.\"\n",
    "    async for event in runner_instance.run_async(user_id=USER_ID, session_id=session_id, new_message=user_content):\n",
    "        # print(f\"Event: {event.type}, Author: {event.author}\") # Uncomment for detailed logging\n",
    "        if event.is_final_response() and event.content and event.content.parts:\n",
    "            # For output_schema, the content is the JSON string itself\n",
    "            final_response_content = event.content.parts[0].text\n",
    "\n",
    "    print(f\"<<< Agent '{agent_instance.name}' Response: {final_response_content}\")\n",
    "\n",
    "    current_session = session_service.get_session(app_name=APP_NAME,\n",
    "                                                  user_id=USER_ID,\n",
    "                                                  session_id=session_id)\n",
    "    stored_output = current_session.state.get(agent_instance.output_key)\n",
    "\n",
    "    # Pretty print if the stored output looks like JSON (likely from output_schema)\n",
    "    print(f\"--- Session State ['{agent_instance.output_key}']: \", end=\"\")\n",
    "    try:\n",
    "        # Attempt to parse and pretty print if it's JSON\n",
    "        parsed_output = json.loads(stored_output)\n",
    "        print(json.dumps(parsed_output, indent=2))\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "         # Otherwise, print as string\n",
    "        print(stored_output)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a690c7",
   "metadata": {},
   "source": [
    "## Step 7: Run Interactions\n",
    "\n",
    "Finally, we will test the agents by sending queries and observing their responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f6f3017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing Agent with Tool ---\n",
      "\n",
      ">>> Calling Agent: 'capital_agent_tool' | Query: {\"country\": \"France\"}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# run in synchronous context\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Testing Agent with Tool ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_and_print(capital_runner, capital_agent_with_tool, SESSION_ID_TOOL_AGENT, \u001b[33m'\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFrance\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m}\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m call_agent_and_print(capital_runner, capital_agent_with_tool, SESSION_ID_TOOL_AGENT, \u001b[33m'\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCanada\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m}\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Testing Agent with Output Schema (No Tool Use) ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mcall_agent_and_print\u001b[39m\u001b[34m(runner_instance, agent_instance, session_id, query_json)\u001b[39m\n\u001b[32m     10\u001b[39m user_content = types.Content(role=\u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m, parts=[types.Part(text=query_json)])\n\u001b[32m     12\u001b[39m final_response_content = \u001b[33m\"\u001b[39m\u001b[33mNo final response received.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m runner_instance.run_async(user_id=USER_ID, session_id=session_id, new_message=user_content):\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# print(f\"Event: {event.type}, Author: {event.author}\") # Uncomment for detailed logging\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event.is_final_response() \u001b[38;5;129;01mand\u001b[39;00m event.content \u001b[38;5;129;01mand\u001b[39;00m event.content.parts:\n\u001b[32m     16\u001b[39m         \u001b[38;5;66;03m# For output_schema, the content is the JSON string itself\u001b[39;00m\n\u001b[32m     17\u001b[39m         final_response_content = event.content.parts[\u001b[32m0\u001b[39m].text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/adk/runners.py:197\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, new_message, run_config)\u001b[39m\n\u001b[32m    189\u001b[39m   \u001b[38;5;28mself\u001b[39m._append_new_message_to_session(\n\u001b[32m    190\u001b[39m       session,\n\u001b[32m    191\u001b[39m       new_message,\n\u001b[32m    192\u001b[39m       invocation_context,\n\u001b[32m    193\u001b[39m       run_config.save_input_blobs_as_artifacts,\n\u001b[32m    194\u001b[39m   )\n\u001b[32m    196\u001b[39m invocation_context.agent = \u001b[38;5;28mself\u001b[39m._find_agent_to_run(session, root_agent)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m invocation_context.agent.run_async(invocation_context):\n\u001b[32m    198\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28mself\u001b[39m.session_service.append_event(session=session, event=event)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/adk/agents/base_agent.py:141\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n\u001b[32m    139\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_async_impl(ctx):\n\u001b[32m    142\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/adk/agents/llm_agent.py:232\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_async_impl\u001b[39m(\n\u001b[32m    230\u001b[39m     \u001b[38;5;28mself\u001b[39m, ctx: InvocationContext\n\u001b[32m    231\u001b[39m ) -> AsyncGenerator[Event, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx):\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:231\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    230\u001b[39m   last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context):\n\u001b[32m    232\u001b[39m     last_event = event\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:257\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# Calls the LLM.\u001b[39;00m\n\u001b[32m    251\u001b[39m model_response_event = Event(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    253\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    254\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    255\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    256\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    258\u001b[39m     invocation_context, llm_request, model_response_event\n\u001b[32m    259\u001b[39m ):\n\u001b[32m    260\u001b[39m   \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    261\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    262\u001b[39m       invocation_context, llm_request, llm_response, model_response_event\n\u001b[32m    263\u001b[39m   ):\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:470\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    466\u001b[39m   \u001b[38;5;66;03m# Check if we can make this llm call or not. If the current call pushes\u001b[39;00m\n\u001b[32m    467\u001b[39m   \u001b[38;5;66;03m# the counter beyond the max set value, then the execution is stopped\u001b[39;00m\n\u001b[32m    468\u001b[39m   \u001b[38;5;66;03m# right here, and exception is thrown.\u001b[39;00m\n\u001b[32m    469\u001b[39m   invocation_context.increment_llm_call_count()\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m llm.generate_content_async(\n\u001b[32m    471\u001b[39m       llm_request,\n\u001b[32m    472\u001b[39m       stream=invocation_context.run_config.streaming_mode\n\u001b[32m    473\u001b[39m       == StreamingMode.SSE,\n\u001b[32m    474\u001b[39m   ):\n\u001b[32m    475\u001b[39m     trace_call_llm(\n\u001b[32m    476\u001b[39m         invocation_context,\n\u001b[32m    477\u001b[39m         model_response_event.id,\n\u001b[32m    478\u001b[39m         llm_request,\n\u001b[32m    479\u001b[39m         llm_response,\n\u001b[32m    480\u001b[39m     )\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/adk/models/google_llm.py:86\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Sends a request to the Gemini model.\u001b[39;00m\n\u001b[32m     73\u001b[39m \n\u001b[32m     74\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \u001b[33;03m  LlmResponse: The model response.\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mself\u001b[39m._maybe_append_user_content(llm_request)\n\u001b[32m     83\u001b[39m logger.info(\n\u001b[32m     84\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mSending out request, model: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, backend: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m, stream: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m     85\u001b[39m     llm_request.model,\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_backend\u001b[49m,\n\u001b[32m     87\u001b[39m     stream,\n\u001b[32m     88\u001b[39m )\n\u001b[32m     89\u001b[39m logger.info(_build_request_log(llm_request))\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/functools.py:1039\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m   1037\u001b[39m val = cache.get(\u001b[38;5;28mself\u001b[39m.attrname, _NOT_FOUND)\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1041\u001b[39m         cache[\u001b[38;5;28mself\u001b[39m.attrname] = val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/adk/models/google_llm.py:161\u001b[39m, in \u001b[36mGemini._api_backend\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_api_backend\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mvertex\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m.vertexai \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mml_dev\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/functools.py:1039\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, instance, owner)\u001b[39m\n\u001b[32m   1037\u001b[39m val = cache.get(\u001b[38;5;28mself\u001b[39m.attrname, _NOT_FOUND)\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     val = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1041\u001b[39m         cache[\u001b[38;5;28mself\u001b[39m.attrname] = val\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/adk/models/google_llm.py:155\u001b[39m, in \u001b[36mGemini.api_client\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapi_client\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Client:\n\u001b[32m    150\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Provides the api client.\u001b[39;00m\n\u001b[32m    151\u001b[39m \n\u001b[32m    152\u001b[39m \u001b[33;03m  Returns:\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[33;03m    The api client.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHttpOptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_headers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/genai/client.py:200\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(http_options, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    198\u001b[39m   http_options = HttpOptions(**http_options)\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[38;5;28mself\u001b[39m._api_client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_api_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug_config\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_debug_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m._aio = AsyncClient(\u001b[38;5;28mself\u001b[39m._api_client)\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._models = Models(\u001b[38;5;28mself\u001b[39m._api_client)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/genai/client.py:245\u001b[39m, in \u001b[36mClient._get_api_client\u001b[39m\u001b[34m(vertexai, api_key, credentials, project, location, debug_config, http_options)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m debug_config \u001b[38;5;129;01mand\u001b[39;00m debug_config.client_mode \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    229\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrecord\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    230\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mreplay\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    231\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    232\u001b[39m ]:\n\u001b[32m    233\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m ReplayApiClient(\n\u001b[32m    234\u001b[39m       mode=debug_config.client_mode,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    235\u001b[39m       replay_id=debug_config.replay_id,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    242\u001b[39m       http_options=http_options,\n\u001b[32m    243\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBaseApiClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvertexai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ai-learning-week-building-llm-apps/.venv/lib/python3.13/site-packages/google/genai/_api_client.py:425\u001b[39m, in \u001b[36mBaseApiClient.__init__\u001b[39m\u001b[34m(self, vertexai, api_key, credentials, project, location, http_options)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Implicit initialization or missing arguments.\u001b[39;00m\n\u001b[32m    424\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_key:\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    426\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mMissing key inputs argument! To use the Google AI API,\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    427\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m provide (`api_key`) arguments. To use the Google Cloud API,\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    428\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m provide (`vertexai`, `project` & `location`) arguments.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    429\u001b[39m     )\n\u001b[32m    430\u001b[39m   \u001b[38;5;28mself\u001b[39m._http_options.base_url = \u001b[33m'\u001b[39m\u001b[33mhttps://generativelanguage.googleapis.com/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    431\u001b[39m   \u001b[38;5;28mself\u001b[39m._http_options.api_version = \u001b[33m'\u001b[39m\u001b[33mv1beta\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Missing key inputs argument! To use the Google AI API, provide (`api_key`) arguments. To use the Google Cloud API, provide (`vertexai`, `project` & `location`) arguments."
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    print(\"--- Testing Agent with Tool ---\")\n",
    "    await call_agent_and_print(capital_runner, capital_agent_with_tool, SESSION_ID_TOOL_AGENT, '{\"country\": \"France\"}')\n",
    "    await call_agent_and_print(capital_runner, capital_agent_with_tool, SESSION_ID_TOOL_AGENT, '{\"country\": \"Canada\"}')\n",
    "\n",
    "    print(\"\\n\\n--- Testing Agent with Output Schema (No Tool Use) ---\")\n",
    "    await call_agent_and_print(structured_runner, structured_info_agent_schema, SESSION_ID_SCHEMA_AGENT, '{\"country\": \"France\"}')\n",
    "    await call_agent_and_print(structured_runner, structured_info_agent_schema, SESSION_ID_SCHEMA_AGENT, '{\"country\": \"Japan\"}')\n",
    "\n",
    "import asyncio\n",
    "# run in synchronous context\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff4ec78",
   "metadata": {},
   "source": [
    "## Recap & Next Steps\n",
    "\n",
    "You've just built and interacted with a basic agent!\n",
    "\n",
    "**Key Concepts:**\n",
    "*   **Tools:** Functions the agent can use.\n",
    "*   **FunctionDeclaration:** Describing tools for the LLM.\n",
    "*   **FunctionCall:** The LLM requesting a tool execution.\n",
    "*   **FunctionResponse:** Providing the tool's result back to the LLM.\n",
    "*   **Multi-turn Conversation:** The interaction often involves back-and-forth between the user, LLM, and tools.\n",
    "\n",
    "> #### ðŸŽ Bonus exercises ðŸ“\n",
    "> - **Add More Tools:** Create another tool (e.g., one that returns the current date) and add its `FunctionDeclaration` to the `tools` list.\n",
    "> - **Error Handling:** What happens if the user asks for division by zero? How could you make the agent handle tool errors more gracefully?\n",
    "> - **Complex Queries:** Try asking multi-step questions like \"What is 5 plus 3, and then multiply the result by 2?\". Does the agent handle it in one go or multiple steps?\n",
    "> - **Explore Frameworks:** Libraries like LangChain or LlamaIndex provide higher-level abstractions for building more complex agents."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
